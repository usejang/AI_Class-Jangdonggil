{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70bf4b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import LeakyReLU, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9237e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./gan_images\"):\n",
    "    os.mkdir(\"./gan_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546f78fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 모델  : pooling 안함\n",
    "generator = Sequential()\n",
    "generator.add(Dense(128*7*7,input_dim=100, activation=LeakyReLU(0.2)))\n",
    "generator.add(BatchNormalization())   # 정규화 -> 분산 1이 되도록 재배치\n",
    "generator.add(Reshape((7,7,128)))  # 배열 reshape\n",
    "generator.add(UpSampling2D())   # 사이즈 업\n",
    "generator.add(Conv2D(64, kernel_size=5, padding='same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Activation(LeakyReLU(0.2)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(1, kernel_size=5,padding='same', activation='tanh' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a688508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자 모델  : 학습 안함\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=2, input_shape=(28,28,1),\n",
    "                 padding='same', activation=LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Conv2D(128,kernel_size=5,strides=2,padding='same'))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "discriminator.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85ff377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 28, 28, 1)         865281    \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 1)                 212865    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,078,146\n",
      "Trainable params: 852,609\n",
      "Non-trainable params: 225,537\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 생성자와 판별자 모델을 연결시키는 gan 모델 생성\n",
    "ginput = Input(shape=(100,))\n",
    "goutput = discriminator(generator(ginput)) \n",
    "gan = Model(ginput, goutput)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "gan.summary()\n",
    "# gan.train_on_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58236a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망을 실행시키는 함수를 정의\n",
    "def gan_train(epoch, batch_size, saving_interval):\n",
    "    # MNIST 데이터 불러오기\n",
    "    (X_train,_), (_,_) = mnist.load_data()  # train의 이미지만 필요함\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "    # 픽셀값이 0 ~ 255 => -1 ~ 1 로 변환\n",
    "    X_train = ( X_train - 127.5) / 127.5\n",
    "    \n",
    "    # 실데이터와 가상 데이터의 타겟 생성 \n",
    "    true = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    # 생성된 이미지와 실제 이미지 비교 학습 ( epoch 만큼 )\n",
    "    for i in range(epoch):\n",
    "        # 실제 이미지를 판별자에 입력\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)  # 인덱스 랜덤\n",
    "        imgs = X_train[idx]  # 이미지를 랜덤하게 batch_size만큼 가져옴\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, true)\n",
    "        \n",
    "        # 가상 이미지를 판별자에 입력\n",
    "        noise = np.random.normal(0, 1, (batch_size,100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        \n",
    "        # 판별자와 생성자의 오차 계산\n",
    "        d_loss = np.add(d_loss_real, d_loss_fake) * 0.5\n",
    "        g_loss = gan.train_on_batch(noise, true)\n",
    "        # 오차 출력\n",
    "        print('epoch:%d' %i, ' d_loss:%.4f' % d_loss, ' g_loss:%.4f' % g_loss)\n",
    "        \n",
    "        # 중간에 이미지 저장 : 5 * 5개의 이미지를 저장\n",
    "        if i % saving_interval == 0:\n",
    "            noise = np.random.normal(0, 1, (25,100))\n",
    "            gen_imgs = generator.predict(noise)\n",
    "            gen_imgs = gen_imgs * 0.5 + 0.5\n",
    "            \n",
    "            fig, axs = plt.subplots(5, 5)\n",
    "            count = 0\n",
    "            for j in range(5):\n",
    "                for k in range(5):\n",
    "                    axs[j, k].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n",
    "                    axs[j, k].axis('off')\n",
    "                    count += 1\n",
    "            fig.savefig(\"gan_images/gan_mnist_%d.png\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6432b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0  d_loss:0.6879  g_loss:0.5430\n",
      "epoch:1  d_loss:0.4394  g_loss:0.1530\n",
      "epoch:2  d_loss:0.4066  g_loss:0.0173\n",
      "epoch:3  d_loss:0.4756  g_loss:0.0045\n",
      "epoch:4  d_loss:0.5134  g_loss:0.0060\n",
      "epoch:5  d_loss:0.5364  g_loss:0.0388\n",
      "epoch:6  d_loss:0.4489  g_loss:0.2404\n",
      "epoch:7  d_loss:0.4870  g_loss:0.4736\n",
      "epoch:8  d_loss:0.5123  g_loss:0.4979\n",
      "epoch:9  d_loss:0.5047  g_loss:0.4203\n",
      "epoch:10  d_loss:0.4365  g_loss:0.4966\n",
      "epoch:11  d_loss:0.4166  g_loss:0.7088\n",
      "epoch:12  d_loss:0.3471  g_loss:1.1423\n",
      "epoch:13  d_loss:0.3312  g_loss:1.7042\n",
      "epoch:14  d_loss:0.3390  g_loss:2.1136\n",
      "epoch:15  d_loss:0.4726  g_loss:1.7082\n",
      "epoch:16  d_loss:0.5518  g_loss:1.0929\n",
      "epoch:17  d_loss:0.6324  g_loss:0.8172\n",
      "epoch:18  d_loss:0.5525  g_loss:1.0656\n",
      "epoch:19  d_loss:0.4065  g_loss:1.1238\n",
      "epoch:20  d_loss:0.4399  g_loss:0.7258\n",
      "epoch:21  d_loss:0.3018  g_loss:0.5959\n",
      "epoch:22  d_loss:0.2178  g_loss:0.6494\n",
      "epoch:23  d_loss:0.1455  g_loss:1.0400\n",
      "epoch:24  d_loss:0.1868  g_loss:0.7990\n",
      "epoch:25  d_loss:0.1772  g_loss:0.5084\n",
      "epoch:26  d_loss:0.2366  g_loss:1.0210\n",
      "epoch:27  d_loss:0.4250  g_loss:0.7325\n",
      "epoch:28  d_loss:0.3994  g_loss:0.9908\n",
      "epoch:29  d_loss:0.6530  g_loss:0.5324\n",
      "epoch:30  d_loss:0.4898  g_loss:1.0984\n",
      "epoch:31  d_loss:0.8560  g_loss:0.4785\n",
      "epoch:32  d_loss:0.7671  g_loss:0.6540\n",
      "epoch:33  d_loss:0.8574  g_loss:0.5902\n",
      "epoch:34  d_loss:0.8222  g_loss:0.5676\n",
      "epoch:35  d_loss:0.6120  g_loss:0.9097\n",
      "epoch:36  d_loss:0.5611  g_loss:1.0169\n",
      "epoch:37  d_loss:0.2899  g_loss:1.0694\n",
      "epoch:38  d_loss:0.2176  g_loss:1.3199\n",
      "epoch:39  d_loss:0.1227  g_loss:1.8178\n",
      "epoch:40  d_loss:0.1063  g_loss:2.2278\n",
      "epoch:41  d_loss:0.1552  g_loss:2.2851\n",
      "epoch:42  d_loss:0.0957  g_loss:2.6417\n",
      "epoch:43  d_loss:0.1818  g_loss:3.5409\n",
      "epoch:44  d_loss:0.3601  g_loss:3.2664\n",
      "epoch:45  d_loss:0.6026  g_loss:3.5540\n",
      "epoch:46  d_loss:1.0597  g_loss:3.2659\n",
      "epoch:47  d_loss:0.7983  g_loss:3.9416\n",
      "epoch:48  d_loss:1.6221  g_loss:2.5585\n",
      "epoch:49  d_loss:0.9569  g_loss:2.2736\n",
      "epoch:50  d_loss:0.8445  g_loss:1.9705\n",
      "epoch:51  d_loss:0.8190  g_loss:1.8457\n",
      "epoch:52  d_loss:0.8981  g_loss:1.3977\n",
      "epoch:53  d_loss:0.7718  g_loss:1.2213\n",
      "epoch:54  d_loss:0.7180  g_loss:1.1842\n",
      "epoch:55  d_loss:0.5921  g_loss:1.1146\n",
      "epoch:56  d_loss:0.5271  g_loss:1.1475\n",
      "epoch:57  d_loss:0.4944  g_loss:1.0653\n",
      "epoch:58  d_loss:0.5133  g_loss:0.9867\n",
      "epoch:59  d_loss:0.4573  g_loss:1.0847\n",
      "epoch:60  d_loss:0.4344  g_loss:1.2138\n",
      "epoch:61  d_loss:0.3602  g_loss:1.2350\n",
      "epoch:62  d_loss:0.3153  g_loss:1.2962\n",
      "epoch:63  d_loss:0.2782  g_loss:1.1617\n",
      "epoch:64  d_loss:0.3180  g_loss:1.4398\n",
      "epoch:65  d_loss:0.3171  g_loss:1.3657\n",
      "epoch:66  d_loss:0.2136  g_loss:1.4361\n",
      "epoch:67  d_loss:0.2402  g_loss:1.3077\n",
      "epoch:68  d_loss:0.2030  g_loss:1.4781\n",
      "epoch:69  d_loss:0.2295  g_loss:1.3535\n",
      "epoch:70  d_loss:0.1642  g_loss:1.6177\n",
      "epoch:71  d_loss:0.2038  g_loss:1.6942\n",
      "epoch:72  d_loss:0.1989  g_loss:1.2500\n",
      "epoch:73  d_loss:0.3018  g_loss:0.9387\n",
      "epoch:74  d_loss:0.1187  g_loss:1.2823\n",
      "epoch:75  d_loss:0.1716  g_loss:1.0751\n",
      "epoch:76  d_loss:0.2945  g_loss:0.8945\n",
      "epoch:77  d_loss:0.1638  g_loss:0.6568\n",
      "epoch:78  d_loss:0.2675  g_loss:0.4808\n",
      "epoch:79  d_loss:0.2015  g_loss:0.4223\n",
      "epoch:80  d_loss:0.3892  g_loss:0.6399\n",
      "epoch:81  d_loss:0.4878  g_loss:0.6379\n",
      "epoch:82  d_loss:0.2269  g_loss:0.7439\n",
      "epoch:83  d_loss:0.5683  g_loss:0.5300\n",
      "epoch:84  d_loss:0.5384  g_loss:0.4724\n",
      "epoch:85  d_loss:0.4691  g_loss:0.5611\n",
      "epoch:86  d_loss:0.7053  g_loss:0.4902\n",
      "epoch:87  d_loss:0.7299  g_loss:0.5325\n",
      "epoch:88  d_loss:1.0872  g_loss:0.6143\n",
      "epoch:89  d_loss:1.1673  g_loss:0.5947\n",
      "epoch:90  d_loss:0.8677  g_loss:0.7346\n",
      "epoch:91  d_loss:0.7969  g_loss:0.7073\n",
      "epoch:92  d_loss:0.8236  g_loss:0.7551\n",
      "epoch:93  d_loss:0.6909  g_loss:0.7083\n",
      "epoch:94  d_loss:0.5411  g_loss:0.8985\n",
      "epoch:95  d_loss:0.4359  g_loss:1.0249\n",
      "epoch:96  d_loss:0.3154  g_loss:1.4643\n",
      "epoch:97  d_loss:0.2199  g_loss:1.8670\n",
      "epoch:98  d_loss:0.2156  g_loss:1.8535\n",
      "epoch:99  d_loss:0.1357  g_loss:2.0478\n",
      "epoch:100  d_loss:0.1119  g_loss:2.4232\n",
      "epoch:101  d_loss:0.1499  g_loss:2.1197\n",
      "epoch:102  d_loss:0.1683  g_loss:2.4263\n",
      "epoch:103  d_loss:0.1387  g_loss:2.4094\n",
      "epoch:104  d_loss:0.2133  g_loss:2.2512\n",
      "epoch:105  d_loss:0.1942  g_loss:2.9534\n",
      "epoch:106  d_loss:0.3047  g_loss:3.4392\n",
      "epoch:107  d_loss:0.3694  g_loss:3.3655\n",
      "epoch:108  d_loss:0.6869  g_loss:2.4030\n",
      "epoch:109  d_loss:0.7126  g_loss:1.9945\n",
      "epoch:110  d_loss:0.5030  g_loss:2.5373\n",
      "epoch:111  d_loss:0.9865  g_loss:2.5910\n",
      "epoch:112  d_loss:1.0905  g_loss:1.9604\n",
      "epoch:113  d_loss:0.8074  g_loss:1.7434\n",
      "epoch:114  d_loss:0.9738  g_loss:1.8587\n",
      "epoch:115  d_loss:0.8736  g_loss:1.7493\n",
      "epoch:116  d_loss:0.7894  g_loss:1.6850\n",
      "epoch:117  d_loss:0.6979  g_loss:1.6773\n",
      "epoch:118  d_loss:0.7177  g_loss:1.5491\n",
      "epoch:119  d_loss:0.8624  g_loss:1.4141\n",
      "epoch:120  d_loss:0.6755  g_loss:1.4494\n",
      "epoch:121  d_loss:0.6459  g_loss:1.4994\n",
      "epoch:122  d_loss:0.6913  g_loss:1.5799\n",
      "epoch:123  d_loss:0.6244  g_loss:1.4646\n",
      "epoch:124  d_loss:0.6557  g_loss:1.4262\n",
      "epoch:125  d_loss:0.5585  g_loss:1.4349\n",
      "epoch:126  d_loss:0.6642  g_loss:1.3811\n",
      "epoch:127  d_loss:0.5859  g_loss:1.3277\n",
      "epoch:128  d_loss:0.6669  g_loss:1.4188\n",
      "epoch:129  d_loss:0.5744  g_loss:1.6060\n",
      "epoch:130  d_loss:0.6132  g_loss:1.6076\n",
      "epoch:131  d_loss:0.6003  g_loss:1.3911\n",
      "epoch:132  d_loss:0.5550  g_loss:1.5023\n",
      "epoch:133  d_loss:0.5631  g_loss:1.4222\n",
      "epoch:134  d_loss:0.5211  g_loss:1.4985\n",
      "epoch:135  d_loss:0.5398  g_loss:1.4260\n",
      "epoch:136  d_loss:0.5780  g_loss:1.5950\n",
      "epoch:137  d_loss:0.5138  g_loss:1.6188\n",
      "epoch:138  d_loss:0.5368  g_loss:1.4151\n",
      "epoch:139  d_loss:0.5267  g_loss:1.3590\n",
      "epoch:140  d_loss:0.5161  g_loss:1.2892\n",
      "epoch:141  d_loss:0.4593  g_loss:1.2358\n",
      "epoch:142  d_loss:0.4613  g_loss:1.3827\n",
      "epoch:143  d_loss:0.5057  g_loss:1.6008\n",
      "epoch:144  d_loss:0.4293  g_loss:1.5429\n",
      "epoch:145  d_loss:0.4806  g_loss:1.3839\n",
      "epoch:146  d_loss:0.4333  g_loss:1.3798\n",
      "epoch:147  d_loss:0.4293  g_loss:1.2407\n",
      "epoch:148  d_loss:0.4375  g_loss:1.5607\n",
      "epoch:149  d_loss:0.3532  g_loss:1.2080\n",
      "epoch:150  d_loss:0.4473  g_loss:1.2643\n",
      "epoch:151  d_loss:0.3921  g_loss:1.3348\n",
      "epoch:152  d_loss:0.4239  g_loss:1.0964\n",
      "epoch:153  d_loss:0.4626  g_loss:1.1813\n",
      "epoch:154  d_loss:0.4267  g_loss:1.2762\n",
      "epoch:155  d_loss:0.5638  g_loss:1.2662\n",
      "epoch:156  d_loss:0.4163  g_loss:1.3710\n",
      "epoch:157  d_loss:0.4074  g_loss:1.2423\n",
      "epoch:158  d_loss:0.5620  g_loss:1.3159\n",
      "epoch:159  d_loss:0.4537  g_loss:1.1881\n",
      "epoch:160  d_loss:0.4106  g_loss:1.3019\n",
      "epoch:161  d_loss:0.4735  g_loss:1.2510\n",
      "epoch:162  d_loss:0.3852  g_loss:1.0546\n",
      "epoch:163  d_loss:0.5155  g_loss:1.0667\n"
     ]
    }
   ],
   "source": [
    "gan_train(4001, 32, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34230213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
